{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2504a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib numpy scikit-learn seaborn nltk opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Autoencoder to implement anomaly detection. Build the model by using:\n",
    "# a. Import required libraries\n",
    "# b. Upload / access the dataset\n",
    "# c. Encoder converts it into latent representation\n",
    "# d. Decoder networks convert it back to the original input\n",
    "# e. Compile the models with Optimizer, Loss, and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7dfd20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All required libraries imported successfully!\n",
      "AUTOENCODER ANOMALY DETECTION - SYNTHETIC ECG DATASET\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "STAGE b: DATASET LOADING AND PREPROCESSING\n",
      "============================================================\n",
      "Generating synthetic ECG data...\n",
      "Dataset shape: (5000, 140)\n",
      "Labels shape: (5000,)\n",
      "\n",
      "Dataset Information:\n",
      "Number of samples: 5000\n",
      "Time steps per sample: 140\n",
      "\n",
      "Label Distribution:\n",
      "Class 0 (Normal): 4000 samples (80.0%)\n",
      "Class 1 (PVC): 250 samples (5.0%)\n",
      "Class 2 (Tachycardia): 250 samples (5.0%)\n",
      "Class 3 (Bradycardia): 250 samples (5.0%)\n",
      "Class 4 (AFib): 250 samples (5.0%)\n",
      "\n",
      "Normal samples (Class 0): 4000\n",
      "Anomalous samples (Classes 1-4): 1000\n",
      "\n",
      "Data splits:\n",
      "Training data (normal only): (3200, 140)\n",
      "Validation data (normal only): (800, 140)\n",
      "Test data: (5000, 140)\n",
      "Test labels - Normal: 4000, Anomalous: 1000\n",
      "\n",
      "============================================================\n",
      "STAGE c: BUILDING ENCODER NETWORK\n",
      "============================================================\n",
      "Encoder Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_bn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ latent_space (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_dense1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m18,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dropout1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dense2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dropout2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_dense3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ encoder_bn3 (\u001b[38;5;33mBatchNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ latent_space (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,808</span> (116.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,808\u001b[0m (116.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,360</span> (114.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,360\u001b[0m (114.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STAGE d: BUILDING DECODER NETWORK\n",
      "============================================================\n",
      "Decoder Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ decoder_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_bn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,060</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ decoder_dense1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dropout1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dense2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dropout2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_dense3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_bn3 (\u001b[38;5;33mBatchNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder_output (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m)                 │          \u001b[38;5;34m18,060\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,932</span> (116.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,932\u001b[0m (116.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,484</span> (115.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,484\u001b[0m (115.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STAGE e: BUILDING AND COMPILING AUTOENCODER\n",
      "============================================================\n",
      "Autoencoder Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,932</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ Encoder (\u001b[38;5;33mSequential\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │          \u001b[38;5;34m29,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Decoder (\u001b[38;5;33mSequential\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m)                 │          \u001b[38;5;34m29,932\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,740</span> (233.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m59,740\u001b[0m (233.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,844</span> (229.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m58,844\u001b[0m (229.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Compilation Details:\n",
      "Optimizer: Adam (learning_rate=0.001)\n",
      "Loss Function: Mean Squared Error (MSE)\n",
      "Metrics: Mean Absolute Error (MAE)\n",
      "\n",
      "============================================================\n",
      "TRAINING AUTOENCODER\n",
      "============================================================\n",
      "Training Parameters:\n",
      "Batch size: 32\n",
      "Epochs: 100\n",
      "Training samples: 3200\n",
      "Validation samples: 800\n",
      "Epoch 1/100\n",
      "\u001b[1m 53/100\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0511 - mae: 0.1813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AUTOENCODER FOR ANOMALY DETECTION - SYNTHETIC ECG DATASET\n",
    "==========================================================\n",
    "Fixed implementation with synthetic ECG data to avoid URL issues\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# a. IMPORT REQUIRED LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, classification_report, \n",
    "                           roc_curve, auc, precision_recall_curve)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"✅ All required libraries imported successfully!\")\n",
    "\n",
    "# =============================================================================\n",
    "# b. UPLOAD / ACCESS THE DATASET - SYNTHETIC ECG DATA\n",
    "# =============================================================================\n",
    "\n",
    "def generate_synthetic_ecg_data(n_samples=5000, sequence_length=140, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic ECG-like data for demonstration\n",
    "    \"\"\"\n",
    "    print(\"Generating synthetic ECG data...\")\n",
    "    \n",
    "    t = np.linspace(0, 4*np.pi, sequence_length)\n",
    "    \n",
    "    # Generate different types of ECG patterns\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Class 0: Normal sinus rhythm (majority class)\n",
    "        if i < 4000:  # 80% normal\n",
    "            # Normal ECG pattern\n",
    "            ecg = (np.sin(t) + \n",
    "                   0.5 * np.sin(2*t) + \n",
    "                   0.2 * np.sin(3*t) +\n",
    "                   0.1 * np.random.normal(0, noise_level, sequence_length))\n",
    "            label = 0\n",
    "        \n",
    "        # Class 1-4: Various anomalies (20% total)\n",
    "        elif i < 4250:  # 5% - PVC (Premature Ventricular Contraction)\n",
    "            ecg = (0.7 * np.sin(1.5*t) + \n",
    "                   0.3 * np.sin(3*t) +\n",
    "                   0.4 * np.random.normal(0, noise_level*2, sequence_length))\n",
    "            label = 1\n",
    "        \n",
    "        elif i < 4500:  # 5% - Tachycardia\n",
    "            ecg = (1.2 * np.sin(1.8*t) + \n",
    "                   0.3 * np.sin(2*t) +\n",
    "                   0.1 * np.random.normal(0, noise_level, sequence_length))\n",
    "            label = 2\n",
    "        \n",
    "        elif i < 4750:  # 5% - Bradycardia\n",
    "            ecg = (0.6 * np.sin(0.8*t) + \n",
    "                   0.2 * np.sin(1.5*t) +\n",
    "                   0.1 * np.random.normal(0, noise_level, sequence_length))\n",
    "            label = 3\n",
    "        \n",
    "        else:  # 5% - Atrial Fibrillation\n",
    "            ecg = (0.8 * np.sin(t + 0.5*np.sin(0.5*t)) + \n",
    "                   0.4 * np.random.normal(0, noise_level*3, sequence_length))\n",
    "            label = 4\n",
    "        \n",
    "        data.append(ecg)\n",
    "        labels.append(label)\n",
    "    \n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Normalize data\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess the synthetic ECG dataset for anomaly detection\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE b: DATASET LOADING AND PREPROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Generate synthetic ECG data\n",
    "    data, labels = generate_synthetic_ecg_data()\n",
    "    \n",
    "    print(f\"Dataset shape: {data.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    \n",
    "    # Display dataset information\n",
    "    print(\"\\nDataset Information:\")\n",
    "    print(f\"Number of samples: {len(data)}\")\n",
    "    print(f\"Time steps per sample: {data.shape[1]}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    label_names = ['Normal', 'PVC', 'Tachycardia', 'Bradycardia', 'AFib']\n",
    "    \n",
    "    print(\"\\nLabel Distribution:\")\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        print(f\"Class {label} ({label_names[label]}): {count} samples ({count/len(labels)*100:.1f}%)\")\n",
    "    \n",
    "    # Prepare data for anomaly detection\n",
    "    # Class 0: Normal heartbeats, Classes 1-4: Anomalous heartbeats\n",
    "    normal_data = data[labels == 0]  # Normal samples\n",
    "    anomalous_data = data[labels != 0]  # Anomalous samples\n",
    "    \n",
    "    print(f\"\\nNormal samples (Class 0): {len(normal_data)}\")\n",
    "    print(f\"Anomalous samples (Classes 1-4): {len(anomalous_data)}\")\n",
    "    \n",
    "    # Normalize the data (already normalized, but ensure proper scaling)\n",
    "    scaler = MinMaxScaler()\n",
    "    normal_data_scaled = scaler.fit_transform(normal_data)\n",
    "    anomalous_data_scaled = scaler.transform(anomalous_data)\n",
    "    all_data_scaled = scaler.transform(data)\n",
    "    \n",
    "    # Split normal data for training and validation\n",
    "    train_data, val_data = train_test_split(\n",
    "        normal_data_scaled, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create test set with both normal and anomalous samples\n",
    "    test_data = np.vstack([normal_data_scaled, anomalous_data_scaled])\n",
    "    test_labels = np.array([0] * len(normal_data_scaled) + [1] * len(anomalous_data_scaled))\n",
    "    \n",
    "    print(f\"\\nData splits:\")\n",
    "    print(f\"Training data (normal only): {train_data.shape}\")\n",
    "    print(f\"Validation data (normal only): {val_data.shape}\")\n",
    "    print(f\"Test data: {test_data.shape}\")\n",
    "    print(f\"Test labels - Normal: {sum(test_labels == 0)}, Anomalous: {sum(test_labels == 1)}\")\n",
    "    \n",
    "    return (train_data, val_data, test_data, test_labels, \n",
    "            normal_data_scaled, anomalous_data_scaled, scaler, data.shape[1], label_names)\n",
    "\n",
    "# =============================================================================\n",
    "# c. ENCODER NETWORK - LATENT REPRESENTATION\n",
    "# =============================================================================\n",
    "\n",
    "def build_encoder(input_dim, latent_dim=32):\n",
    "    \"\"\"\n",
    "    Build encoder network that converts input to latent representation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE c: BUILDING ENCODER NETWORK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    encoder = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,), name='encoder_input'),\n",
    "        \n",
    "        # First encoding layer\n",
    "        layers.Dense(128, activation='relu', name='encoder_dense1'),\n",
    "        layers.BatchNormalization(name='encoder_bn1'),\n",
    "        layers.Dropout(0.2, name='encoder_dropout1'),\n",
    "        \n",
    "        # Second encoding layer\n",
    "        layers.Dense(64, activation='relu', name='encoder_dense2'),\n",
    "        layers.BatchNormalization(name='encoder_bn2'),\n",
    "        layers.Dropout(0.2, name='encoder_dropout2'),\n",
    "        \n",
    "        # Third encoding layer\n",
    "        layers.Dense(32, activation='relu', name='encoder_dense3'),\n",
    "        layers.BatchNormalization(name='encoder_bn3'),\n",
    "        \n",
    "        # Latent space representation\n",
    "        layers.Dense(latent_dim, activation='relu', name='latent_space')\n",
    "    ], name='Encoder')\n",
    "    \n",
    "    print(\"Encoder Architecture:\")\n",
    "    encoder.summary()\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "# =============================================================================\n",
    "# d. DECODER NETWORK - RECONSTRUCTION\n",
    "# =============================================================================\n",
    "\n",
    "def build_decoder(output_dim, latent_dim=32):\n",
    "    \"\"\"\n",
    "    Build decoder network that converts latent representation back to original input\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE d: BUILDING DECODER NETWORK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    decoder = models.Sequential([\n",
    "        layers.Input(shape=(latent_dim,), name='decoder_input'),\n",
    "        \n",
    "        # First decoding layer\n",
    "        layers.Dense(32, activation='relu', name='decoder_dense1'),\n",
    "        layers.BatchNormalization(name='decoder_bn1'),\n",
    "        layers.Dropout(0.2, name='decoder_dropout1'),\n",
    "        \n",
    "        # Second decoding layer\n",
    "        layers.Dense(64, activation='relu', name='decoder_dense2'),\n",
    "        layers.BatchNormalization(name='decoder_bn2'),\n",
    "        layers.Dropout(0.2, name='decoder_dropout2'),\n",
    "        \n",
    "        # Third decoding layer\n",
    "        layers.Dense(128, activation='relu', name='decoder_dense3'),\n",
    "        layers.BatchNormalization(name='decoder_bn3'),\n",
    "        \n",
    "        # Output layer - reconstruct original input\n",
    "        layers.Dense(output_dim, activation='sigmoid', name='decoder_output')\n",
    "    ], name='Decoder')\n",
    "    \n",
    "    print(\"Decoder Architecture:\")\n",
    "    decoder.summary()\n",
    "    \n",
    "    return decoder\n",
    "\n",
    "# =============================================================================\n",
    "# e. COMPILE MODELS WITH OPTIMIZER, LOSS, AND EVALUATION METRICS\n",
    "# =============================================================================\n",
    "\n",
    "def build_and_compile_autoencoder(encoder, decoder, input_dim):\n",
    "    \"\"\"\n",
    "    Build and compile the complete autoencoder model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE e: BUILDING AND COMPILING AUTOENCODER\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create autoencoder model\n",
    "    autoencoder = models.Sequential([\n",
    "        encoder,\n",
    "        decoder\n",
    "    ], name='Autoencoder')\n",
    "    \n",
    "    # Compile the model\n",
    "    autoencoder.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',  # Mean Squared Error for reconstruction\n",
    "        metrics=['mae']  # Mean Absolute Error as additional metric\n",
    "    )\n",
    "    \n",
    "    print(\"Autoencoder Architecture:\")\n",
    "    autoencoder.summary()\n",
    "    \n",
    "    print(\"\\nModel Compilation Details:\")\n",
    "    print(f\"Optimizer: Adam (learning_rate=0.001)\")\n",
    "    print(f\"Loss Function: Mean Squared Error (MSE)\")\n",
    "    print(f\"Metrics: Mean Absolute Error (MAE)\")\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL TRAINING AND EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def train_autoencoder(autoencoder, train_data, val_data):\n",
    "    \"\"\"\n",
    "    Train the autoencoder model\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING AUTOENCODER\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    \n",
    "    print(f\"Training Parameters:\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Training samples: {len(train_data)}\")\n",
    "    print(f\"Validation samples: {len(val_data)}\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = autoencoder.fit(\n",
    "        train_data, train_data,  # Autoencoder: input = target\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(val_data, val_data),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    return history\n",
    "\n",
    "def evaluate_anomaly_detection(autoencoder, test_data, test_labels, threshold=None):\n",
    "    \"\"\"\n",
    "    Evaluate the autoencoder for anomaly detection\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANOMALY DETECTION EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get reconstructions\n",
    "    reconstructions = autoencoder.predict(test_data, verbose=0)\n",
    "    \n",
    "    # Calculate reconstruction error (MSE per sample)\n",
    "    reconstruction_errors = np.mean(np.square(test_data - reconstructions), axis=1)\n",
    "    \n",
    "    # Determine optimal threshold if not provided\n",
    "    if threshold is None:\n",
    "        # Use 95th percentile of training reconstruction errors as threshold\n",
    "        normal_indices = test_labels == 0\n",
    "        normal_errors = reconstruction_errors[normal_indices]\n",
    "        threshold = np.percentile(normal_errors, 95)\n",
    "    \n",
    "    # Make predictions (1 = anomaly, 0 = normal)\n",
    "    predictions = (reconstruction_errors > threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    \n",
    "    print(\"Anomaly Detection Results:\")\n",
    "    print(f\"Threshold: {threshold:.6f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, predictions, \n",
    "                              target_names=['Normal', 'Anomaly']))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Normal', 'Anomaly'],\n",
    "                yticklabels=['Normal', 'Anomaly'])\n",
    "    plt.title('Confusion Matrix - Anomaly Detection', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('anomaly_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot reconstruction error distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    normal_errors = reconstruction_errors[test_labels == 0]\n",
    "    anomalous_errors = reconstruction_errors[test_labels == 1]\n",
    "    \n",
    "    plt.hist(normal_errors, bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "    plt.hist(anomalous_errors, bins=50, alpha=0.7, label='Anomalous', color='red')\n",
    "    plt.axvline(threshold, color='black', linestyle='--', label=f'Threshold: {threshold:.4f}')\n",
    "    plt.xlabel('Reconstruction Error (MSE)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Reconstruction Errors')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return reconstruction_errors, predictions, threshold, {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Autoencoder Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot MAE\n",
    "    ax2.plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "    ax2.set_title('Autoencoder Training MAE', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('autoencoder_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_reconstructions(autoencoder, normal_data, anomalous_data, num_samples=5):\n",
    "    \"\"\"Visualize original vs reconstructed signals\"\"\"\n",
    "    # Select samples\n",
    "    normal_samples = normal_data[:num_samples]\n",
    "    anomalous_samples = anomalous_data[:num_samples]\n",
    "    \n",
    "    # Get reconstructions\n",
    "    normal_recon = autoencoder.predict(normal_samples, verbose=0)\n",
    "    anomalous_recon = autoencoder.predict(anomalous_samples, verbose=0)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
    "    \n",
    "    # Plot normal samples\n",
    "    for i in range(num_samples):\n",
    "        if num_samples > 1:\n",
    "            ax = axes[0, i]\n",
    "        else:\n",
    "            ax = axes[0]\n",
    "        ax.plot(normal_samples[i], 'b-', label='Original', linewidth=2)\n",
    "        ax.plot(normal_recon[i], 'r--', label='Reconstructed', linewidth=2)\n",
    "        ax.set_title(f'Normal Sample {i+1}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot anomalous samples\n",
    "    for i in range(num_samples):\n",
    "        if num_samples > 1:\n",
    "            ax = axes[1, i]\n",
    "        else:\n",
    "            ax = axes[1]\n",
    "        ax.plot(anomalous_samples[i], 'b-', label='Original', linewidth=2)\n",
    "        ax.plot(anomalous_recon[i], 'r--', label='Reconstructed', linewidth=2)\n",
    "        ax.set_title(f'Anomalous Sample {i+1}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reconstruction_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_latent_space(encoder, test_data, test_labels):\n",
    "    \"\"\"Visualize the latent space representation\"\"\"\n",
    "    # Get latent representations\n",
    "    latent_representations = encoder.predict(test_data, verbose=0)\n",
    "    \n",
    "    # If latent dimension > 2, use PCA to reduce to 2D\n",
    "    if latent_representations.shape[1] > 2:\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        latent_2d = pca.fit_transform(latent_representations)\n",
    "        print(f\"Explained variance by 2 principal components: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "    else:\n",
    "        latent_2d = latent_representations\n",
    "    \n",
    "    # Plot latent space\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], \n",
    "                         c=test_labels, cmap='viridis', alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Anomaly (0=Normal, 1=Anomaly)')\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title('Latent Space Representation')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('latent_space.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the complete autoencoder anomaly detection pipeline\n",
    "    \"\"\"\n",
    "    print(\"AUTOENCODER ANOMALY DETECTION - SYNTHETIC ECG DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # b. Load and preprocess dataset\n",
    "        (train_data, val_data, test_data, test_labels, \n",
    "         normal_data, anomalous_data, scaler, input_dim, label_names) = load_and_preprocess_data()\n",
    "        \n",
    "        # c. Build encoder\n",
    "        latent_dim = 16\n",
    "        encoder = build_encoder(input_dim, latent_dim)\n",
    "        \n",
    "        # d. Build decoder\n",
    "        decoder = build_decoder(input_dim, latent_dim)\n",
    "        \n",
    "        # e. Build and compile autoencoder\n",
    "        autoencoder = build_and_compile_autoencoder(encoder, decoder, input_dim)\n",
    "        \n",
    "        # Train autoencoder\n",
    "        history = train_autoencoder(autoencoder, train_data, val_data)\n",
    "        \n",
    "        # Plot training history\n",
    "        plot_training_history(history)\n",
    "        \n",
    "        # Evaluate anomaly detection\n",
    "        reconstruction_errors, predictions, threshold, metrics = evaluate_anomaly_detection(\n",
    "            autoencoder, test_data, test_labels\n",
    "        )\n",
    "        \n",
    "        # Visualize reconstructions\n",
    "        visualize_reconstructions(autoencoder, normal_data, anomalous_data)\n",
    "        \n",
    "        # Visualize latent space\n",
    "        visualize_latent_space(encoder, test_data, test_labels)\n",
    "        \n",
    "        # Save models\n",
    "        autoencoder.save('autoencoder_anomaly_detection.h5')\n",
    "        encoder.save('encoder_model.h5')\n",
    "        decoder.save('decoder_model.h5')\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FINAL SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Final Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"Final F1-Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"Optimal Threshold: {metrics['threshold']:.6f}\")\n",
    "        print(f\"Models saved: autoencoder_anomaly_detection.h5, encoder_model.h5, decoder_model.h5\")\n",
    "        print(\"Anomaly detection pipeline completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7296b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timewaste",
   "language": "python",
   "name": "timewaste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
