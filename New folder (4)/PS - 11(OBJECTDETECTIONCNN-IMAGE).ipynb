{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1640d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib numpy scikit-learn seaborn nltk opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583688aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection using Transfer Learning of CNN architectures for the given (image dataset\n",
    "# 3) using the below steps:\n",
    "# a. Load in a pre-trained CNN model trained on a large dataset\n",
    "# b. Freeze parameters (weights) in model's lower convolutional layers\n",
    "# c. Add custom classifier with several layers of trainable parameters to model\n",
    "# d. Train classifier layers on training data available for task\n",
    "# e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes less time but efficient for cpu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=== COMPREHENSIVE VGG16 TRANSFER LEARNING ===\")\n",
    "print(\"With detailed visualizations and analysis\")\n",
    "\n",
    "def extract_features_and_train_comprehensive():\n",
    "    \"\"\"\n",
    "    Extract features once and train on pre-computed features with comprehensive outputs\n",
    "    \"\"\"\n",
    "    data_path = \"caltech-101-img\"\n",
    "    \n",
    "    # Step 1: Load VGG16 for feature extraction\n",
    "    print(\"Step a: Loading VGG16 for feature extraction...\")\n",
    "    feature_extractor = VGG16(\n",
    "        weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "        include_top=False,\n",
    "        input_shape=(64, 64, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    feature_extractor.trainable = False\n",
    "    \n",
    "    # Step 2: Create data generators\n",
    "    print(\"Step b: Creating data generators...\")\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    \n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        data_path, target_size=(64, 64), batch_size=32, \n",
    "        class_mode='categorical', subset='training', shuffle=False\n",
    "    )\n",
    "    \n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        data_path, target_size=(64, 64), batch_size=32,\n",
    "        class_mode='categorical', subset='validation', shuffle=False\n",
    "    )\n",
    "    \n",
    "    num_classes = len(train_gen.class_indices)\n",
    "    class_names = list(train_gen.class_indices.keys())\n",
    "    print(f\"Classes: {num_classes}\")\n",
    "    \n",
    "    # Step 3: Extract features\n",
    "    print(\"Step c: Extracting features from VGG16...\")\n",
    "    \n",
    "    # Extract training features\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    train_filenames = []\n",
    "    \n",
    "    print(\"Extracting training features...\")\n",
    "    for i, (x_batch, y_batch) in enumerate(train_gen):\n",
    "        if i >= len(train_gen):\n",
    "            break\n",
    "        features = feature_extractor.predict(x_batch, verbose=0)\n",
    "        train_features.extend(features)\n",
    "        train_labels.extend(y_batch)\n",
    "        train_filenames.extend(train_gen.filenames[i * train_gen.batch_size:(i + 1) * train_gen.batch_size])\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(train_gen)} training batches\")\n",
    "    \n",
    "    # Extract validation features\n",
    "    val_features = []\n",
    "    val_labels = []\n",
    "    val_filenames = []\n",
    "    \n",
    "    print(\"Extracting validation features...\")\n",
    "    for i, (x_batch, y_batch) in enumerate(val_gen):\n",
    "        if i >= len(val_gen):\n",
    "            break\n",
    "        features = feature_extractor.predict(x_batch, verbose=0)\n",
    "        val_features.extend(features)\n",
    "        val_labels.extend(y_batch)\n",
    "        val_filenames.extend(val_gen.filenames[i * val_gen.batch_size:(i + 1) * val_gen.batch_size])\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(val_gen)} validation batches\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_train = np.array(train_features)\n",
    "    y_train = np.array(train_labels)\n",
    "    X_val = np.array(val_features)\n",
    "    y_val = np.array(val_labels)\n",
    "    \n",
    "    print(f\"Training features: {X_train.shape}\")\n",
    "    print(f\"Validation features: {X_val.shape}\")\n",
    "    \n",
    "    # Step 4: Build and train classifier\n",
    "    print(\"Step d: Training classifier on extracted features...\")\n",
    "    classifier = models.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=(512,)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    classifier.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Training classifier...\")\n",
    "    start_time = time.time()\n",
    "    history = classifier.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=15,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Classifier trained in {training_time:.1f} seconds!\")\n",
    "    \n",
    "    # Step 5: Create final model\n",
    "    print(\"Step e: Creating final model...\")\n",
    "    final_model = models.Sequential([\n",
    "        feature_extractor,\n",
    "        classifier\n",
    "    ])\n",
    "    \n",
    "    # ========== COMPREHENSIVE VISUALIZATIONS ==========\n",
    "    \n",
    "    # 1. Training History Plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title('Model Accuracy Progress', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss Progress', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Final Evaluation\n",
    "    print(\"\\n=== COMPREHENSIVE EVALUATION ===\")\n",
    "    val_loss, val_accuracy = classifier.evaluate(X_val, y_val, verbose=0)\n",
    "    train_loss, train_accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # 3. Predictions and Analysis\n",
    "    print(\"\\nGenerating predictions and analysis...\")\n",
    "    y_pred = classifier.predict(X_val, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = np.mean(y_true_classes == y_pred_classes)\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    \n",
    "    # 4. Confusion Matrix for Top 10 Classes (FIXED VERSION)\n",
    "    print(\"\\nGenerating confusion matrix for top 10 classes...\")\n",
    "    \n",
    "    # Select top 10 most frequent classes in validation set\n",
    "    unique, counts = np.unique(y_true_classes, return_counts=True)\n",
    "    top_10_indices = unique[np.argsort(-counts)[:10]]  # Top 10 by frequency\n",
    "    top_10_classes = [class_names[i] for i in top_10_indices]\n",
    "    \n",
    "    print(f\"Top 10 classes by frequency: {top_10_classes}\")\n",
    "    \n",
    "    # Filter for top 10 classes - only include samples where BOTH true and pred are in top 10\n",
    "    mask_true = np.isin(y_true_classes, top_10_indices)\n",
    "    mask_pred = np.isin(y_pred_classes, top_10_indices)\n",
    "    mask_combined = mask_true & mask_pred\n",
    "    \n",
    "    y_true_filtered = y_true_classes[mask_combined]\n",
    "    y_pred_filtered = y_pred_classes[mask_combined]\n",
    "    \n",
    "    print(f\"Samples in confusion matrix: {len(y_true_filtered)}\")\n",
    "    \n",
    "    if len(y_true_filtered) > 0:\n",
    "        # Create mapping for confusion matrix\n",
    "        label_map = {old_idx: new_idx for new_idx, old_idx in enumerate(top_10_indices)}\n",
    "        y_true_mapped = np.array([label_map[int(idx)] for idx in y_true_filtered])  # Convert to int\n",
    "        y_pred_mapped = np.array([label_map[int(idx)] for idx in y_pred_filtered])  # Convert to int\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        cm = confusion_matrix(y_true_mapped, y_pred_mapped)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=top_10_classes, yticklabels=top_10_classes)\n",
    "        plt.title('Confusion Matrix - Top 10 Most Frequent Classes', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Classification Report for filtered data\n",
    "        print(\"\\nClassification Report (Top 10 Most Frequent Classes):\")\n",
    "        print(classification_report(y_true_mapped, y_pred_mapped, \n",
    "                                  target_names=top_10_classes, digits=3, zero_division=0))\n",
    "    else:\n",
    "        print(\"Not enough samples for confusion matrix\")\n",
    "    \n",
    "    # 5. Sample Predictions Visualization\n",
    "    print(\"\\nGenerating sample predictions visualization...\")\n",
    "    # Get a sample of validation predictions\n",
    "    sample_indices = np.random.choice(len(X_val), min(12, len(X_val)), replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        \n",
    "        # Get original image\n",
    "        img_path = os.path.join(data_path, val_filenames[idx])\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=(64, 64))\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "                plt.imshow(img_array)\n",
    "            except:\n",
    "                plt.imshow(np.zeros((64, 64, 3)))\n",
    "        else:\n",
    "            plt.imshow(np.zeros((64, 64, 3)))\n",
    "        \n",
    "        plt.axis('off')\n",
    "        \n",
    "        true_class = class_names[y_true_classes[idx]]\n",
    "        pred_class = class_names[y_pred_classes[idx]]\n",
    "        confidence = np.max(y_pred[idx])\n",
    "        \n",
    "        # Truncate long class names\n",
    "        true_class_short = true_class[:15] + '...' if len(true_class) > 15 else true_class\n",
    "        pred_class_short = pred_class[:15] + '...' if len(pred_class) > 15 else pred_class\n",
    "        \n",
    "        color = 'green' if y_true_classes[idx] == y_pred_classes[idx] else 'red'\n",
    "        plt.title(f'True: {true_class_short}\\nPred: {pred_class_short}\\nConf: {confidence:.3f}', \n",
    "                 color=color, fontsize=8, pad=3)\n",
    "    \n",
    "    plt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Accuracy Distribution by Class\n",
    "    print(\"\\nCalculating per-class accuracy...\")\n",
    "    class_accuracy = {}\n",
    "    class_counts = {}\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_mask = y_true_classes == class_idx\n",
    "        class_count = np.sum(class_mask)\n",
    "        if class_count > 0:\n",
    "            class_acc = np.mean(y_pred_classes[class_mask] == class_idx)\n",
    "            class_accuracy[class_name] = class_acc\n",
    "            class_counts[class_name] = class_count\n",
    "    \n",
    "    # Sort classes by accuracy\n",
    "    sorted_classes = sorted(class_accuracy.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Plot top 15 classes by accuracy\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_15_classes = [cls[0] for cls in sorted_classes[:15]]\n",
    "    top_15_accuracies = [cls[1] for cls in sorted_classes[:15]]\n",
    "    \n",
    "    colors = ['green' if acc > 0.7 else 'orange' if acc > 0.5 else 'red' for acc in top_15_accuracies]\n",
    "    bars = plt.barh(top_15_classes, top_15_accuracies, color=colors, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title('Top 15 Classes by Accuracy', fontsize=14, fontweight='bold')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, top_15_accuracies):\n",
    "        plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{acc:.3f}', va='center', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 7. Class Distribution Chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    class_names_short = [name[:20] + '...' if len(name) > 20 else name for name in class_names[:20]]\n",
    "    class_counts_vals = [class_counts.get(name, 0) for name in class_names[:20]]\n",
    "    \n",
    "    plt.bar(range(len(class_names_short)), class_counts_vals, color='skyblue', alpha=0.7)\n",
    "    plt.title('Class Distribution (Top 20 Classes)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.xticks(range(len(class_names_short)), class_names_short, rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 8. Performance Summary\n",
    "    print(\"\\n=== PERFORMANCE SUMMARY ===\")\n",
    "    print(f\"{'Metric':<25} {'Value':<10}\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"{'Training Accuracy':<25} {train_accuracy:.4f}\")\n",
    "    print(f\"{'Validation Accuracy':<25} {val_accuracy:.4f}\")\n",
    "    print(f\"{'Training Loss':<25} {train_loss:.4f}\")\n",
    "    print(f\"{'Validation Loss':<25} {val_loss:.4f}\")\n",
    "    print(f\"{'Number of Classes':<25} {num_classes}\")\n",
    "    print(f\"{'Training Samples':<25} {len(X_train):,}\")\n",
    "    print(f\"{'Validation Samples':<25} {len(X_val):,}\")\n",
    "    \n",
    "    # 9. Best and Worst Performing Classes\n",
    "    print(\"\\n=== CLASS PERFORMANCE ANALYSIS ===\")\n",
    "    print(\"Top 5 Best Performing Classes:\")\n",
    "    for i, (cls, acc) in enumerate(sorted_classes[:5]):\n",
    "        count = class_counts[cls]\n",
    "        print(f\"  {i+1}. {cls:<20} {acc:.3f} ({count} samples)\")\n",
    "    \n",
    "    print(\"\\nTop 5 Worst Performing Classes:\")\n",
    "    for i, (cls, acc) in enumerate(sorted_classes[-5:]):\n",
    "        count = class_counts[cls]\n",
    "        print(f\"  {i+1}. {cls:<20} {acc:.3f} ({count} samples)\")\n",
    "    \n",
    "    # 10. Transfer Learning Summary\n",
    "    print(\"\\n=== TRANSFER LEARNING PIPELINE ===\")\n",
    "    print(\"‚úì VGG16 Feature Extractor (Frozen)\")\n",
    "    print(\"‚úì Global Average Pooling\")\n",
    "    print(\"‚úì Dense(256) + ReLU + Dropout(0.3)\")\n",
    "    print(\"‚úì Dense(128) + ReLU + Dropout(0.2)\")\n",
    "    print(f\"‚úì Dense({num_classes}) + Softmax\")\n",
    "    \n",
    "    # Save the model\n",
    "    final_model.save('caltech101_vgg16_comprehensive.h5')\n",
    "    print(f\"\\n‚úì Model saved as 'caltech101_vgg16_comprehensive.h5'\")\n",
    "    \n",
    "    # Final Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ TRANSFER LEARNING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìä Final Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"üè∑Ô∏è  Total Classes: {num_classes}\")\n",
    "    print(f\"üìà Training Samples: {len(X_train):,}\")\n",
    "    print(f\"üß™ Validation Samples: {len(X_val):,}\")\n",
    "    print(f\"‚öôÔ∏è  Model Parameters: {final_model.count_params():,}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return final_model, history, class_names\n",
    "\n",
    "# Run the comprehensive version\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        total_start = time.time()\n",
    "        \n",
    "        model, history, class_names = extract_features_and_train_comprehensive()\n",
    "        \n",
    "        total_time = time.time() - total_start\n",
    "        print(f\"\\n‚è±Ô∏è  TOTAL EXECUTION TIME: {total_time/60:.1f} MINUTES\")\n",
    "        print(\"üìä All visualizations generated successfully!\")\n",
    "        print(\"‚úÖ Model ready for practical exam submission!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Modular VGG16 Transfer Learning with Comprehensive Visualizations\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=== ENHANCED MODULAR VGG16 TRANSFER LEARNING ===\")\n",
    "print(\"With comprehensive visualizations and analysis\")\n",
    "\n",
    "class VGG16TransferLearning:\n",
    "    def __init__(self, data_path=\"caltech-101-img\", img_size=(64, 64), batch_size=32):\n",
    "        self.data_path = data_path\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_extractor = None\n",
    "        self.classifier = None\n",
    "        self.final_model = None\n",
    "        self.history = None\n",
    "        self.class_names = []\n",
    "        \n",
    "    def setup_feature_extractor(self):\n",
    "        \"\"\"Step 1: Setup VGG16 feature extractor\"\"\"\n",
    "        print(\"Step a: Loading VGG16 for feature extraction...\")\n",
    "        self.feature_extractor = VGG16(\n",
    "            weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "            include_top=False,\n",
    "            input_shape=(*self.img_size, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "        self.feature_extractor.trainable = False\n",
    "        print(\"‚úì Feature extractor loaded and frozen\")\n",
    "        \n",
    "    def create_data_generators(self):\n",
    "        \"\"\"Step 2: Create data generators\"\"\"\n",
    "        print(\"Step b: Creating data generators...\")\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255, \n",
    "            validation_split=0.2,\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        self.train_gen = datagen.flow_from_directory(\n",
    "            self.data_path, target_size=self.img_size, batch_size=self.batch_size,\n",
    "            class_mode='categorical', subset='training', shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.val_gen = datagen.flow_from_directory(\n",
    "            self.data_path, target_size=self.img_size, batch_size=self.batch_size,\n",
    "            class_mode='categorical', subset='validation', shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.num_classes = len(self.train_gen.class_indices)\n",
    "        self.class_names = list(self.train_gen.class_indices.keys())\n",
    "        print(f\"‚úì Found {self.num_classes} classes\")\n",
    "        \n",
    "    def extract_features(self):\n",
    "        \"\"\"Step 3: Extract features using VGG16\"\"\"\n",
    "        print(\"Step c: Extracting features from VGG16...\")\n",
    "        \n",
    "        # Extract training features\n",
    "        print(\"Extracting training features...\")\n",
    "        self.X_train, self.y_train, self.train_filenames = self._extract_batch_features(self.train_gen, \"training\")\n",
    "        \n",
    "        # Extract validation features\n",
    "        print(\"Extracting validation features...\")\n",
    "        self.X_val, self.y_val, self.val_filenames = self._extract_batch_features(self.val_gen, \"validation\")\n",
    "        \n",
    "        print(f\"‚úì Training features: {self.X_train.shape}\")\n",
    "        print(f\"‚úì Validation features: {self.X_val.shape}\")\n",
    "        \n",
    "    def _extract_batch_features(self, generator, dataset_type):\n",
    "        \"\"\"Helper method to extract features batch by batch\"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "        filenames = []\n",
    "        \n",
    "        total_batches = len(generator)\n",
    "        for i, (x_batch, y_batch) in enumerate(generator):\n",
    "            if i >= total_batches:\n",
    "                break\n",
    "                \n",
    "            batch_features = self.feature_extractor.predict(x_batch, verbose=0)\n",
    "            features.extend(batch_features)\n",
    "            labels.extend(y_batch)\n",
    "            filenames.extend(generator.filenames[i * self.batch_size:(i + 1) * self.batch_size])\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Processed {i + 1}/{total_batches} {dataset_type} batches\")\n",
    "                \n",
    "        return np.array(features), np.array(labels), filenames\n",
    "    \n",
    "    def build_classifier(self):\n",
    "        \"\"\"Step 4: Build and train classifier on extracted features\"\"\"\n",
    "        print(\"Step d: Building and training classifier...\")\n",
    "        \n",
    "        self.classifier = models.Sequential([\n",
    "            layers.Dense(256, activation='relu', input_shape=(512,)),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.classifier.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(\"Training classifier...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.history = self.classifier.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            epochs=15,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            batch_size=32,\n",
    "            verbose=1,\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "                keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        print(f\"‚úì Classifier trained in {self.training_time:.1f} seconds!\")\n",
    "        \n",
    "    def create_final_model(self):\n",
    "        \"\"\"Step 5: Create final combined model\"\"\"\n",
    "        print(\"Step e: Creating final model...\")\n",
    "        self.final_model = models.Sequential([\n",
    "            self.feature_extractor,\n",
    "            self.classifier\n",
    "        ])\n",
    "        print(\"‚úì Final model created\")\n",
    "        \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        print(\"\\n=== COMPREHENSIVE EVALUATION ===\")\n",
    "        \n",
    "        # Basic metrics\n",
    "        self.val_loss, self.val_accuracy = self.classifier.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "        self.train_loss, self.train_accuracy = self.classifier.evaluate(self.X_train, self.y_train, verbose=0)\n",
    "        \n",
    "        # Predictions\n",
    "        self.y_pred = self.classifier.predict(self.X_val, verbose=0)\n",
    "        self.y_pred_classes = np.argmax(self.y_pred, axis=1)\n",
    "        self.y_true_classes = np.argmax(self.y_val, axis=1)\n",
    "        \n",
    "        return self.val_accuracy\n",
    "\n",
    "class VisualizationEngine:\n",
    "    def __init__(self, model, history, class_names, data):\n",
    "        self.model = model\n",
    "        self.history = history\n",
    "        self.class_names = class_names\n",
    "        self.data = data\n",
    "        \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history with enhanced visuals\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax1.plot(self.history.history['accuracy'], label='Training Accuracy', linewidth=2, color='blue')\n",
    "        ax1.plot(self.history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='red')\n",
    "        ax1.set_title('Model Accuracy Progress', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Accuracy')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        \n",
    "        # Loss plot\n",
    "        ax2.plot(self.history.history['loss'], label='Training Loss', linewidth=2, color='blue')\n",
    "        ax2.plot(self.history.history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
    "        ax2.set_title('Model Loss Progress', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_confusion_matrix(self, top_n=10):\n",
    "        \"\"\"Enhanced confusion matrix for top N classes - FIXED VERSION\"\"\"\n",
    "        y_true = self.data['y_true_classes']\n",
    "        y_pred = self.data['y_pred_classes']\n",
    "        \n",
    "        # Get top N classes by frequency\n",
    "        unique, counts = np.unique(y_true, return_counts=True)\n",
    "        top_indices = unique[np.argsort(-counts)[:top_n]]\n",
    "        top_classes = [self.class_names[i] for i in top_indices]\n",
    "        \n",
    "        print(f\"Top {top_n} classes for confusion matrix: {top_classes}\")\n",
    "        \n",
    "        # Filter samples - only include samples where true label is in top N\n",
    "        mask = np.isin(y_true, top_indices)\n",
    "        y_true_filtered = y_true[mask]\n",
    "        y_pred_filtered = y_pred[mask]\n",
    "        \n",
    "        print(f\"Samples in confusion matrix: {len(y_true_filtered)}\")\n",
    "        \n",
    "        if len(y_true_filtered) > 0:\n",
    "            # Create mapping for confusion matrix - FIXED: convert to int\n",
    "            label_map = {int(old_idx): new_idx for new_idx, old_idx in enumerate(top_indices)}\n",
    "            \n",
    "            # Map labels - FIXED: ensure integer conversion\n",
    "            y_true_mapped = np.array([label_map[int(idx)] for idx in y_true_filtered])\n",
    "            y_pred_mapped = np.array([label_map.get(int(idx), -1) for idx in y_pred_filtered])  # Use -1 for unknown\n",
    "            \n",
    "            # Filter out predictions that aren't in top classes\n",
    "            valid_mask = y_pred_mapped != -1\n",
    "            y_true_mapped = y_true_mapped[valid_mask]\n",
    "            y_pred_mapped = y_pred_mapped[valid_mask]\n",
    "            \n",
    "            print(f\"Valid samples after filtering: {len(y_true_mapped)}\")\n",
    "            \n",
    "            if len(y_true_mapped) > 0:\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                cm = confusion_matrix(y_true_mapped, y_pred_mapped)\n",
    "                \n",
    "                # Normalize confusion matrix\n",
    "                cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                \n",
    "                sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                           xticklabels=top_classes, yticklabels=top_classes,\n",
    "                           cbar_kws={'label': 'Accuracy'})\n",
    "                plt.title(f'Normalized Confusion Matrix - Top {top_n} Classes', fontsize=14, fontweight='bold')\n",
    "                plt.xlabel('Predicted Labels')\n",
    "                plt.ylabel('True Labels')\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.yticks(rotation=0)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Print classification report for these classes\n",
    "                print(f\"\\nClassification Report for Top {top_n} Classes:\")\n",
    "                print(classification_report(y_true_mapped, y_pred_mapped, \n",
    "                                          target_names=top_classes, digits=3, zero_division=0))\n",
    "            else:\n",
    "                print(\"No valid samples for confusion matrix after filtering\")\n",
    "        else:\n",
    "            print(\"Not enough samples for confusion matrix\")\n",
    "        \n",
    "    def plot_sample_predictions(self, num_samples=12):\n",
    "        \"\"\"Enhanced sample predictions with confidence scores\"\"\"\n",
    "        sample_indices = np.random.choice(len(self.data['X_val']), min(num_samples, len(self.data['X_val'])), replace=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            if i >= len(axes):\n",
    "                break\n",
    "                \n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Get original image\n",
    "            img_path = os.path.join(self.data['data_path'], self.data['val_filenames'][idx])\n",
    "            if os.path.exists(img_path):\n",
    "                try:\n",
    "                    img = tf.keras.preprocessing.image.load_img(img_path, target_size=self.data['img_size'])\n",
    "                    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "                    ax.imshow(img_array)\n",
    "                except:\n",
    "                    ax.imshow(np.zeros((*self.data['img_size'], 3)))\n",
    "            else:\n",
    "                ax.imshow(np.zeros((*self.data['img_size'], 3)))\n",
    "            \n",
    "            ax.axis('off')\n",
    "            \n",
    "            true_class = self.class_names[self.data['y_true_classes'][idx]]\n",
    "            pred_class = self.class_names[self.data['y_pred_classes'][idx]]\n",
    "            confidence = np.max(self.data['y_pred'][idx])\n",
    "            is_correct = self.data['y_true_classes'][idx] == self.data['y_pred_classes'][idx]\n",
    "            \n",
    "            # Truncate long names\n",
    "            true_class_short = true_class[:15] + '...' if len(true_class) > 15 else true_class\n",
    "            pred_class_short = pred_class[:15] + '...' if len(pred_class) > 15 else pred_class\n",
    "            \n",
    "            color = 'green' if is_correct else 'red'\n",
    "            status = \"‚úì\" if is_correct else \"‚úó\"\n",
    "            \n",
    "            ax.set_title(f'{status} True: {true_class_short}\\nPred: {pred_class_short}\\nConf: {confidence:.3f}', \n",
    "                        color=color, fontsize=9, pad=3)\n",
    "        \n",
    "        plt.suptitle('Sample Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_class_performance(self, top_n=15):\n",
    "        \"\"\"Enhanced class performance visualization\"\"\"\n",
    "        class_accuracy = {}\n",
    "        class_counts = {}\n",
    "        \n",
    "        for class_idx, class_name in enumerate(self.class_names):\n",
    "            class_mask = self.data['y_true_classes'] == class_idx\n",
    "            class_count = np.sum(class_mask)\n",
    "            if class_count > 0:\n",
    "                class_acc = np.mean(self.data['y_pred_classes'][class_mask] == class_idx)\n",
    "                class_accuracy[class_name] = class_acc\n",
    "                class_counts[class_name] = class_count\n",
    "        \n",
    "        # Sort by accuracy\n",
    "        sorted_classes = sorted(class_accuracy.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_classes = [cls[0] for cls in sorted_classes[:top_n]]\n",
    "        top_accuracies = [cls[1] for cls in sorted_classes[:top_n]]\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        colors = ['green' if acc > 0.7 else 'orange' if acc > 0.5 else 'red' for acc in top_accuracies]\n",
    "        bars = plt.barh(top_classes, top_accuracies, color=colors, alpha=0.7, edgecolor='black')\n",
    "        \n",
    "        plt.xlabel('Accuracy', fontsize=12)\n",
    "        plt.title(f'Top {top_n} Classes by Accuracy', fontsize=14, fontweight='bold')\n",
    "        plt.xlim(0, 1)\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, acc, count in zip(bars, top_accuracies, [class_counts[cls] for cls in top_classes]):\n",
    "            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{acc:.3f} (n={count})', va='center', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return sorted_classes, class_counts\n",
    "        \n",
    "    def plot_feature_space(self, n_samples=1000):\n",
    "        \"\"\"Visualize feature space using t-SNE (if computationally feasible)\"\"\"\n",
    "        try:\n",
    "            if len(self.data['X_val']) > n_samples:\n",
    "                indices = np.random.choice(len(self.data['X_val']), n_samples, replace=False)\n",
    "                features_subset = self.data['X_val'][indices]\n",
    "                labels_subset = self.data['y_true_classes'][indices]\n",
    "            else:\n",
    "                features_subset = self.data['X_val']\n",
    "                labels_subset = self.data['y_true_classes']\n",
    "            \n",
    "            print(\"Computing t-SNE visualization... (This may take a while)\")\n",
    "            tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "            features_2d = tsne.fit_transform(features_subset)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], \n",
    "                                c=labels_subset, cmap='tab20', alpha=0.7, s=10)\n",
    "            plt.colorbar(scatter, label='Class Label')\n",
    "            plt.title('t-SNE Visualization of Feature Space', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('t-SNE Component 1')\n",
    "            plt.ylabel('t-SNE Component 2')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"t-SNE visualization skipped: {e}\")\n",
    "            \n",
    "    def plot_confidence_distribution(self):\n",
    "        \"\"\"Plot confidence distribution for correct vs incorrect predictions\"\"\"\n",
    "        correct_mask = self.data['y_true_classes'] == self.data['y_pred_classes']\n",
    "        correct_confidences = np.max(self.data['y_pred'][correct_mask], axis=1)\n",
    "        incorrect_confidences = np.max(self.data['y_pred'][~correct_mask], axis=1)\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(correct_confidences, bins=30, alpha=0.7, label='Correct', color='green', density=True)\n",
    "        plt.hist(incorrect_confidences, bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "        plt.xlabel('Prediction Confidence')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('Confidence Distribution', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Accuracy by confidence bins\n",
    "        confidence_bins = np.linspace(0, 1, 11)\n",
    "        accuracy_per_bin = []\n",
    "        samples_per_bin = []\n",
    "        \n",
    "        for i in range(len(confidence_bins)-1):\n",
    "            mask = (np.max(self.data['y_pred'], axis=1) >= confidence_bins[i]) & \\\n",
    "                   (np.max(self.data['y_pred'], axis=1) < confidence_bins[i+1])\n",
    "            samples_count = np.sum(mask)\n",
    "            samples_per_bin.append(samples_count)\n",
    "            if samples_count > 0:\n",
    "                accuracy = np.mean(self.data['y_pred_classes'][mask] == self.data['y_true_classes'][mask])\n",
    "                accuracy_per_bin.append(accuracy)\n",
    "            else:\n",
    "                accuracy_per_bin.append(0)\n",
    "        \n",
    "        plt.plot(confidence_bins[:-1] + 0.05, accuracy_per_bin, 'o-', linewidth=2, markersize=6)\n",
    "        plt.xlabel('Confidence Bin')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy vs Confidence', fontweight='bold')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_performance_summary(self, sorted_classes, class_counts, training_time):\n",
    "        \"\"\"Create a comprehensive performance summary\"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Top performing classes\n",
    "        top_classes = [cls[0] for cls in sorted_classes[:5]]\n",
    "        top_accuracies = [cls[1] for cls in sorted_classes[:5]]\n",
    "        \n",
    "        ax1.barh(top_classes, top_accuracies, color='green', alpha=0.7)\n",
    "        ax1.set_xlim(0, 1)\n",
    "        ax1.set_title('Top 5 Performing Classes', fontweight='bold')\n",
    "        ax1.set_xlabel('Accuracy')\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Bottom performing classes\n",
    "        bottom_classes = [cls[0] for cls in sorted_classes[-5:]]\n",
    "        bottom_accuracies = [cls[1] for cls in sorted_classes[-5:]]\n",
    "        \n",
    "        ax2.barh(bottom_classes, bottom_accuracies, color='red', alpha=0.7)\n",
    "        ax2.set_xlim(0, 1)\n",
    "        ax2.set_title('Bottom 5 Performing Classes', fontweight='bold')\n",
    "        ax2.set_xlabel('Accuracy')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Training history summary\n",
    "        final_train_acc = self.history.history['accuracy'][-1]\n",
    "        final_val_acc = self.history.history['val_accuracy'][-1]\n",
    "        best_val_acc = max(self.history.history['val_accuracy'])\n",
    "        \n",
    "        metrics = ['Final Train Acc', 'Final Val Acc', 'Best Val Acc']\n",
    "        values = [final_train_acc, final_val_acc, best_val_acc]\n",
    "        \n",
    "        ax3.bar(metrics, values, color=['blue', 'orange', 'green'], alpha=0.7)\n",
    "        ax3.set_ylim(0, 1)\n",
    "        ax3.set_title('Key Performance Metrics', fontweight='bold')\n",
    "        ax3.set_ylabel('Accuracy')\n",
    "        for i, v in enumerate(values):\n",
    "            ax3.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Class distribution for top 10\n",
    "        top_10_classes = [cls[0] for cls in sorted_classes[:10]]\n",
    "        top_10_counts = [class_counts[cls] for cls in top_10_classes]\n",
    "        \n",
    "        ax4.bar(range(len(top_10_classes)), top_10_counts, color='purple', alpha=0.7)\n",
    "        ax4.set_title('Sample Counts - Top 10 Classes', fontweight='bold')\n",
    "        ax4.set_ylabel('Number of Samples')\n",
    "        ax4.set_xticks(range(len(top_10_classes)))\n",
    "        ax4.set_xticklabels([name[:10] + '...' if len(name) > 10 else name for name in top_10_classes], \n",
    "                           rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def run_comprehensive_pipeline():\n",
    "    \"\"\"Main pipeline execution\"\"\"\n",
    "    total_start = time.time()\n",
    "    \n",
    "    # Initialize model\n",
    "    vgg_model = VGG16TransferLearning()\n",
    "    \n",
    "    # Execute pipeline steps\n",
    "    vgg_model.setup_feature_extractor()\n",
    "    vgg_model.create_data_generators()\n",
    "    vgg_model.extract_features()\n",
    "    vgg_model.build_classifier()\n",
    "    vgg_model.create_final_model()\n",
    "    accuracy = vgg_model.evaluate_model()\n",
    "    \n",
    "    # Prepare data for visualizations\n",
    "    viz_data = {\n",
    "        'X_val': vgg_model.X_val,\n",
    "        'y_true_classes': vgg_model.y_true_classes,\n",
    "        'y_pred_classes': vgg_model.y_pred_classes,\n",
    "        'y_pred': vgg_model.y_pred,\n",
    "        'val_filenames': vgg_model.val_filenames,\n",
    "        'data_path': vgg_model.data_path,\n",
    "        'img_size': vgg_model.img_size\n",
    "    }\n",
    "    \n",
    "    # Create visualization engine\n",
    "    viz_engine = VisualizationEngine(\n",
    "        vgg_model.final_model, \n",
    "        vgg_model.history, \n",
    "        vgg_model.class_names, \n",
    "        viz_data\n",
    "    )\n",
    "    \n",
    "    # Generate comprehensive visualizations\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING COMPREHENSIVE VISUALIZATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    viz_engine.plot_training_history()\n",
    "    viz_engine.plot_confusion_matrix(top_n=10)\n",
    "    viz_engine.plot_sample_predictions(num_samples=12)\n",
    "    sorted_classes, class_counts = viz_engine.plot_class_performance(top_n=15)\n",
    "    viz_engine.plot_confidence_distribution()\n",
    "    viz_engine.plot_performance_summary(sorted_classes, class_counts, vgg_model.training_time)\n",
    "    \n",
    "    # Try t-SNE (can be slow, so optional)\n",
    "    try:\n",
    "        viz_engine.plot_feature_space(n_samples=1000)\n",
    "    except:\n",
    "        print(\"t-SNE visualization skipped due to computational constraints\")\n",
    "    \n",
    "    # Performance summary\n",
    "    total_time = time.time() - total_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéâ TRANSFER LEARNING PIPELINE COMPLETED SUCCESSFULLY! üéâ\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìä Final Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"üè∑Ô∏è  Total Classes: {vgg_model.num_classes}\")\n",
    "    print(f\"üìà Training Samples: {len(vgg_model.X_train):,}\")\n",
    "    print(f\"üß™ Validation Samples: {len(vgg_model.X_val):,}\")\n",
    "    print(f\"‚öôÔ∏è  Model Parameters: {vgg_model.final_model.count_params():,}\")\n",
    "    print(f\"‚è±Ô∏è  Total Execution Time: {total_time/60:.1f} minutes\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Performance analysis\n",
    "    best_val_acc = max(vgg_model.history.history['val_accuracy'])\n",
    "    print(f\"\\nüìà Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"üìâ Final Training Accuracy: {vgg_model.history.history['accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    vgg_model.final_model.save('caltech101_vgg16_enhanced.h5')\n",
    "    print(f\"‚úì Model saved as 'caltech101_vgg16_enhanced.h5'\")\n",
    "    \n",
    "    return vgg_model, viz_engine\n",
    "\n",
    "# Run the enhanced pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        model, visualizer = run_comprehensive_pipeline()\n",
    "        print(\"\\n‚úÖ All visualizations generated successfully!\")\n",
    "        print(\"‚úÖ Model ready for practical exam submission!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timewaste",
   "language": "python",
   "name": "timewaste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
